---
title: "Topic Modeling with nmfkc"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Topic Modeling with nmfkc}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7, 
  fig.height = 5
)
```

## Introduction

Non-negative Matrix Factorization (NMF) is a powerful technique for topic modeling. This vignette demonstrates how to use the `nmfkc` package to discover latent topics in the U.S. presidential inaugural addresses using the `quanteda` package.

We will cover:

1.  **Standard NMF**: Basic topic extraction.
2.  **Rank Selection**: Determining the optimal number of topics.
3.  **Kernel NMF**: Modeling temporal topic evolution using covariates.

First, let's load the necessary packages.

```{r load-packages}
library(nmfkc)
library(quanteda)
```

## 1\. Data Preparation

We create a Document-Feature Matrix (DFM) where rows represent documents and columns represent words.

```{r data-prep}
# Load the corpus
corp <- corpus(data_corpus_inaugural)

# Preprocessing: tokenize, remove stopwords, select meaningful words
tok <- tokens(corp)
tok <- tokens_remove(tok, pattern = stopwords("en", source = "snowball"))
df <- dfm(tok)
df <- dfm_select(df, min_nchar = 3) # Remove short words
df <- dfm_trim(df, min_termfreq = 50) # Remove rare words (appearing < 50 times)

# Convert to matrix and transpose for NMF (Features x Samples)
d <- as.matrix(df)
Y <- t(d)

dim(Y) # Features (Words) x Samples (Documents)
```

## 2\. Rank Selection (Determining Number of Topics)

Before fitting the model, we need to decide the number of topics ($rank$). The `nmfkc.rank()` function helps us choose an appropriate rank by evaluating indices like **Element-wise Cross-Validation (ECV)** and **R-squared (Elbow)**.

```{r rank-selection, fig.width=7, fig.height=6}
# Evaluate ranks from 2 to 6
# save.time=FALSE enables Element-wise CV (Robust but slower)
# Here we use save.time=TRUE for speed in this vignette
nmfkc.rank(Y, rank = 2:6, save.time = TRUE)
```

Based on the diagnostics (e.g., the elbow of R-squared or high Cophenetic Correlation), let's assume **Rank = 3** is a reasonable choice for this example.

## 3\. Standard NMF

We fit the standard NMF model with `rank = 3`.

```{r model-fit}
rank <- 3
res_std <- nmfkc(Y, rank = rank, prefix = "Topic")

# Check R-squared
res_std$r.squared
```

### Interpreting Topics (Top Words)

We can identify the meaning of each topic by looking at the words with the highest weights in the basis matrix `X`.

```{r interpret-topics}
# Extract top 10 words for each topic
Xp <- res_std$X.prob
for(k in 1:rank){
  top_words <- names(sort(Xp[,k], decreasing = TRUE)[1:10])
  cat(paste0("Topic ", k, ": ", paste(top_words, collapse = ", "), "\n"))
}
```

## 4\. Kernel NMF: Temporal Topic Evolution

One of the unique features of `nmfkc` is **Kernel NMF**.
In standard NMF, the order of documents is ignored. However, inaugural addresses have a strong temporal component. By using the "Year" as a covariate, we can extract **smoothly evolving topics**.

### optimizing the Kernel Parameter

We construct a covariate matrix `U` using the year of the address. We then find the optimal kernel bandwidth (`beta`) using Cross-Validation.

```{r kernel-prep}
# Covariate: Year of the address
years <- as.numeric(substring(names(data_corpus_inaugural), 1, 4))
U <- t(as.matrix(years))

# Optimize beta (Gaussian Kernel width)
# We test a range of betas around a heuristic median distance
beta_med <- nmfkc.kernel.beta.nearest.med(U)$beta
beta_candidates <- beta_med * c(0.1, 0.5, 1, 2, 10)

cv_res <- nmfkc.kernel.beta.cv(Y, rank = rank, U = U, beta = beta_candidates, plot = FALSE)
best_beta <- cv_res$beta
```

### Fitting Kernel NMF

Now we fit the model using the kernel matrix `A`.

```{r kernel-fit}
# Create Kernel Matrix
A <- nmfkc.kernel(U, beta = best_beta)

# Fit NMF with Kernel Covariates
res_ker <- nmfkc(Y, A = A, rank = rank, prefix = "Topic")
```

### Visualization: Standard vs Kernel NMF

Let's compare how topic proportions change over time.
**Standard NMF** (Top) shows noisy fluctuations, while **Kernel NMF** (Bottom) reveals smooth historical trends.

```{r plot-comparison, fig.width=8, fig.height=8}
par(mfrow = c(2, 1), mar = c(4, 4, 2, 1))

# 1. Standard NMF (Noisy)
barplot(res_std$B.prob, col = 2:(rank+1), border = NA, xaxt='n',
        main = "Standard NMF: Topic Proportions", ylab = "Probability")
axis(1, at = seq(1, ncol(Y), length.out = 10), labels = seq(min(years), max(years), length.out = 10))

# 2. Kernel NMF (Smooth trend)
barplot(res_ker$B.prob, col = 2:(rank+1), border = NA, xaxt='n',
        main = "Kernel NMF: Temporal Topic Evolution", ylab = "Probability")
axis(1, at = seq(1, ncol(Y), length.out = 10), labels = seq(min(years), max(years), length.out = 10))

# Legend
legend("topright", legend = paste("Topic", 1:rank), fill = 2:(rank+1), bg="white", cex=0.8)
```

The Kernel NMF results clearly show how political themes have shifted smoothly over American history (e.g., from early nation-building to modern global issues).

