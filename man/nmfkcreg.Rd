% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nmfkcreg.R
\name{nmfkcreg}
\alias{nmfkcreg}
\title{Optimizing NMF (Non-negative Matrix Factorization) with kernel covariates regression}
\usage{
nmfkcreg(
  Y,
  A = diag(ncol(Y)),
  Q = 2,
  gamma = 0,
  epsilon = 1e-04,
  maxit = 5000,
  method = "EU",
  trace = FALSE,
  dims = TRUE
)
}
\arguments{
\item{Y}{observation matrix}

\item{A}{covariate matrix. Without covariate, identity matrix is used.
Or matrix A(R,N) having N columns can be accepted.
kernel matrix A(N,N) can be created by create.kernel function.}

\item{Q}{rank of basis matrix and Q<=min(P,N)}

\item{gamma}{penalty parameter for C(Q,R) in objective function}

\item{epsilon}{positive convergence tolerance}

\item{maxit}{maximum number of iterations}

\item{method}{default objective function is Euclid distance "EU", otherwise Kullbackâ€“Leibler divergence "KL"}

\item{trace}{display current iteration every 10 times if trace=TRUE}

\item{dims}{display dimensions of matrix sizes if dim=TRUE}
}
\value{
X(P,Q): basis matrix whose column sum is 1

C(Q,R): parameter matrix

B(Q,N): B(Q,N)=C(Q,R)A(R,N) regression coefficient matrix

XB(P,N): XB(P,N)=X(P,Q)B(Q,N) prediction matrix or fitted values for observation matrix Y

P(Q,N): probability matrix whose column sum is 1
for soft clustering based on regression coefficient matrix B(Q,N).

cluster: the number of the basis that takes the maximum value of each column of P(Q,N)
for hard clustering

objfunc: last objective function

objfunc.iter: objective function at each iteration

r.squared: coefficient of determination R^2, squared correlation between Y(P,N) and XB(P,N)
}
\description{
\code{nmkcfreg} The goal of the package is to perform NMF (Non-negative Matrix Factorization) with kernel covariates regression described by Y(P,N)~X(P,Q)C(Q,R)A(R,N)
where observation matrix Y(P,N),
covariate matrix A(R,N),
basis matrix X(P,Q) whose column sum is 1 and Q<=min(P,N)
and coefficient matrix C(Q,R).
Note that Y(N,P) and A(R,N) are known, and X(P,Q) and C(Q,R) are unknown.
}
\examples{
library(nmfkcreg)
Y <- t(iris[,-5])
result <- nmfkcreg(Y,Q=2)
# visualization of some results
plot(result$objfunc.iter) # convergence

# goodness of fit
plot(as.vector(result$XB),as.vector(Y),
main=paste0("r.squared=",round(result$r.squared,3)))
abline(a=0,b=1,col=2)

# dimension reduction based on regression coefficient B
plot(t(result$B))
}
