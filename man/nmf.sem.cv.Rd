% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nmfkc.R
\name{nmf.sem.cv}
\alias{nmf.sem.cv}
\title{Cross-Validation for NMF-SEM}
\usage{
nmf.sem.cv(
  Y1,
  Y2,
  rank = NULL,
  X.init = NULL,
  X.L2.ortho = 100,
  C1.L1 = 0.5,
  C2.L1 = 0,
  epsilon = 1e-04,
  maxit = 50000,
  seed = NULL,
  div = 5,
  shuffle = TRUE,
  ...
)
}
\arguments{
\item{Y1}{A non-negative numeric matrix of endogenous variables with
\strong{rows = variables (P1), columns = samples (N)}.}

\item{Y2}{A non-negative numeric matrix of exogenous variables with
\strong{rows = variables (P2), columns = samples (N)}.
Must satisfy \code{ncol(Y1) == ncol(Y2)}.}

\item{rank}{Integer; rank (number of latent factors) passed to \code{nmf.sem}.
If \code{NULL}, \code{nmf.sem} decides the effective rank (via \code{...} or \code{nrow(Y2)}).}

\item{X.init}{Optional initialization for \code{X} (as in \code{nmf.sem}).}

\item{X.L2.ortho}{L2 orthogonality penalty for \code{X}.}

\item{C1.L1}{L1 sparsity penalty for \code{C1} (\eqn{\Theta_1}).}

\item{C2.L1}{L1 sparsity penalty for \code{C2} (\eqn{\Theta_2}).}

\item{epsilon}{Convergence threshold for \code{nmf.sem}.}

\item{maxit}{Maximum number of iterations for \code{nmf.sem}.}

\item{seed}{Master random seed for CV splitting and fold-specific calls to \code{nmf.sem}.
If \code{NULL}, RNG is not controlled within folds.}

\item{div}{Number of CV folds. (Default: \code{5})}

\item{shuffle}{Logical; if \code{TRUE}, samples are randomly permuted
before assigning to folds. (Default: \code{TRUE})}

\item{...}{Additional arguments passed to \code{nmf.sem} (except for
\code{rank}, \code{seed}, \code{div}, \code{shuffle}, which are handled here).}
}
\value{
A numeric scalar: mean MAE across CV folds.
}
\description{
Performs K-fold cross-validation to evaluate the equilibrium mapping of
the NMF-SEM model.

For each fold, \code{nmf.sem} is fitted on the training samples,
yielding an equilibrium mapping \eqn{\hat Y_1 = M_{\mathrm{model}} Y_2}.
The held-out endogenous variables \eqn{Y_1} are then predicted from \eqn{Y_2}
using this mapping, and the mean absolute error (MAE) over all entries in the
test block is computed. The returned value is the average MAE across folds.

This implements the hyperparameter selection strategy described in the paper:
hyperparameters are chosen by predictive cross-validation rather than direct
inspection of the internal structural matrices.
}
