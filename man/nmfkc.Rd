% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nmfkc.R
\name{nmfkc}
\alias{nmfkc}
\title{Optimizing NMF (Non-negative Matrix Factorization) with Kernel Covariate}
\source{
Satoh, K. (2024) Applying Non-negative Matrix Factorization with Covariates to the Longitudinal Data as Growth Curve Model. arXiv preprint arXiv:2403.05359. \url{https://arxiv.org/abs/2403.05359}
}
\usage{
nmfkc(
  Y,
  A = NULL,
  Q = 2,
  gamma = 0,
  epsilon = 1e-04,
  maxit = 5000,
  method = "EU",
  X.column = "sum",
  nstart = 1,
  hclust.method = "average",
  print.trace = FALSE,
  print.dims = TRUE,
  save.time = TRUE
)
}
\arguments{
\item{Y}{observation matrix}

\item{A}{covariate matrix. The default is NULL if without covariate.}

\item{Q}{rank of basis matrix and Q<=min(P,N)}

\item{gamma}{penalty parameter for parameter matrix C}

\item{epsilon}{positive convergence tolerance}

\item{maxit}{maximum number of iterations}

\item{method}{The default objective function is Euclid distance "EU", otherwise Kullbackâ€“Leibler divergence "KL"}

\item{X.column}{The default is X.column="sum" and the column sum of basis matrix is 1, and it is interpreted as probability. The column of basis matrix is unit vector when X.column="squared".}

\item{nstart}{The default is one. It is the "nstart" option of "kmeans" function used for the initial values of basis matrix.}

\item{hclust.method}{option of hclust for calculating Cophenetic distances}

\item{print.trace}{display current iteration every 10 times if print.trace=TRUE}

\item{print.dims}{display dimensions of matrix sizes if print.dim=TRUE. The default is set by  print.dim=FALSE.}

\item{save.time}{The default is TRUE. Some return values including CPCC are skipped to save the computation time.}
}
\value{
X: basis matrix. The column sum depends on X.column.

B: coefficient matrix, B=CA

B.prob: probability matrix for soft clustering based on coefficient matrix B. Those column sum is 1.

B.prob.mean.min: minimum mean of row vectors of B.prob.

B.cluster: the number of the basis that takes the maximum value of each column of B.prob for hard clustering

XB: fitted values for observation matrix Y

C: parameter matrix

objfunc: last objective function

objfunc.iter: objective function at each iteration

r.squared: coefficient of determination R^2, squared correlation between Y and XB

CPCC: Cophenetic correlation coefficient based on B.prob
}
\description{
\code{nmfkc} The goal of the package is to perform NMF (Non-negative Matrix Factorization) with Kernel Covariate described by Y~XCA=XB
where observation matrix Y(P,N),
covariate matrix A(R,N),
basis matrix X(P,Q) and Q<=min(P,N),
parameter matrix C(Q,R)
and coefficient matrix B(Q,N).
Note that Y(N,P) and A(R,N) are given, and X(P,Q) and C(Q,R) are unknown.
}
\examples{
# install.packages("remotes")
# remotes::install_github("ksatohds/nmfkc")
# Example 1.
library(nmfkc)
Y <- t(iris[,-5])
Q <- 2
result <- nmfkc(Y,Q=Q)
# visualization of some results
plot(result$objfunc.iter) # convergence
# goodness of fit
plot(as.vector(result$XB),as.vector(Y),
main=paste0("r.squared=",round(result$r.squared,3)))
abline(a=0,b=1,col=2)
# dimension reduction based on coefficient matrix B
plot(t(result$B))
# soft clustering based on coefficient matrix B
plot(t(result$B),col=as.numeric(iris$Species))
legend("topright",legend=1:Q,fill=1:Q+1)
stars(t(result$B.prob),locations=t(result$B),scale=FALSE,
  draw.segments=TRUE,col.segments=1:Q+1,len=0.2,add=TRUE)

# Example 2.
Y <- matrix(cars$dist,nrow=1)
A <- rbind(1,cars$speed)
result <- nmfkc(Y,A,Q=1)
plot(as.vector(A[2,]),as.vector(Y))
lines(as.vector(A[2,]),as.vector(result$XB),col=2,lwd=2)
}
\references{
Ding, C., Li, T., Peng, W. and Park, H. (2006) Orthogonal Nonnegative Matrix Tri-Factorizations for Clustering, Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, 126-135. \url{https://doi.org/10.1145/1150402.1150420}

Potthoff, R.F. and Roy, S.N. (1964). A generalized multivariate analysis of variance model useful especially for growth curve problems. Biometrika, 51, 313-326. \url{https://doi.org/10.2307/2334137}
}
