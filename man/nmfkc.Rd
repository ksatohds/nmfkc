% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nmfkc.R
\name{nmfkc}
\alias{nmfkc}
\title{Optimize NMF with kernel covariates}
\source{
Satoh, K. (2024). Applying Non-negative Matrix Factorization with Covariates
to the Longitudinal Data as Growth Curve Model. arXiv:2403.05359.
\url{https://arxiv.org/abs/2403.05359}
}
\usage{
nmfkc(Y, A = NULL, rank = NULL, data, epsilon = 1e-04, maxit = 5000, ...)
}
\arguments{
\item{Y}{Observation matrix, OR a formula object if \code{data} is supplied.}

\item{A}{Covariate matrix. Default is \code{NULL} (no covariates).}

\item{rank}{Integer. The rank of the basis matrix \eqn{X} (Q). Preferred over \code{Q}.}

\item{data}{Optional. A data frame from which variables in the formula should be taken.}

\item{epsilon}{Positive convergence tolerance.}

\item{maxit}{Maximum number of iterations.}

\item{...}{Additional arguments passed for fine-tuning regularization, initialization, constraints,
and output control. This includes the backward-compatible arguments \code{Q} and \code{method}.
\itemize{
\item \code{X.L2.ortho}: Nonnegative penalty parameter for the orthogonality of \eqn{X} (default: 0).
Enforces columns of \eqn{X} to be orthogonal (conceptually \eqn{X^\top X \to I}). (Formerly \code{lambda.ortho}).
\item \code{B.L1}: Nonnegative penalty parameter for L1 regularization on \eqn{B = C A} (default: 0).
Promotes \strong{sparsity in the coefficients}. (Formerly \code{gamma}).
\item \code{C.L1}: Nonnegative penalty parameter for L1 regularization on \eqn{C} (default: 0).
Promotes \strong{sparsity in the parameter matrix}. (Formerly \code{lambda}).
\item \code{Q}: Backward-compatible name for the rank of the basis matrix (Q).
\item \code{method}: Objective function: Euclidean distance \code{"EU"} (default) or Kullback–Leibler divergence \code{"KL"}.
\item \code{X.restriction}: Constraint for columns of \eqn{X}. Options: \code{"colSums"} (default), \code{"colSqSums"}, \code{"totalSum"}, or \code{"fixed"}.
\item \code{X.init}: Method for initializing the basis matrix \eqn{X}. Options: \code{"kmeans"} (default), \code{"runif"}, \code{"nndsvd"}, or a user-specified matrix.
\item \code{nstart}: Number of random starts for \code{kmeans} when initializing \eqn{X} (default: 1).
\item \code{seed}: Integer seed for reproducibility (default: 123).
\item \code{prefix}: Prefix for column names of \eqn{X} and row names of \eqn{B} (default: "Basis").
\item \code{print.trace}: Logical. If \code{TRUE}, prints progress every 10 iterations (default: \code{FALSE}).
\item \code{print.dims}: Logical. If \code{TRUE} (default), prints matrix dimensions and elapsed time.
\item \code{save.time}: Logical. If \code{TRUE} (default), skips some post-computations (e.g., CPCC, silhouette) to save time.
\item \code{save.memory}: Logical. If \code{TRUE}, performs only essential computations (implies \code{save.time = TRUE}) to reduce memory usage (default: \code{FALSE}).
}}
}
\value{
A list with components:
\item{call}{The matched call, as captured by \code{match.call()}.}
\item{dims}{A character string summarizing the matrix dimensions of the model.}
\item{runtime}{A character string summarizing the computation time.}
\item{X}{Basis matrix. Column normalization depends on \code{X.restriction}.}
\item{B}{Coefficient matrix \eqn{B = C A}.}
\item{XB}{Fitted values for \eqn{Y}.}
\item{C}{Parameter matrix.}
\item{B.prob}{Soft-clustering probabilities derived from columns of \eqn{B}.}
\item{B.cluster}{Hard-clustering labels (argmax over \eqn{B.prob} for each column).}
\item{X.prob}{Row-wise soft-clustering probabilities derived from \eqn{X}.}
\item{X.cluster}{Hard-clustering labels (argmax over \eqn{X.prob} for each row).}
\item{objfunc}{Final objective value.}
\item{objfunc.iter}{Objective values by iteration.}
\item{r.squared}{Coefficient of determination \eqn{R^2} between \eqn{Y} and \eqn{X B}.}
\item{sigma}{The residual standard error, representing the typical deviation of the observed values \eqn{Y} from the fitted values \eqn{X B}.}
\item{criterion}{A list of selection criteria, including \code{ICp}, \code{CPCC}, \code{silhouette}, \code{AIC}, and \code{BIC}.}
}
\description{
\code{nmfkc} fits a nonnegative matrix factorization with kernel covariates
under the tri-factorization model \eqn{Y \approx X C A = X B}.

This function supports two major input modes:
\enumerate{
\item \strong{Matrix Mode (Existing)}: \code{nmfkc(Y=matrix, A=matrix, ...)}
\item \strong{Formula Mode (New)}: \code{nmfkc(formula=Y_vars ~ A_vars, data=df, rank=Q, ...)}
}

The rank of the basis matrix can be specified using either the \code{rank} argument
(preferred for formula mode) or the hidden \code{Q} argument (for backward compatibility).
}
\examples{
# install.packages("remotes")
# remotes::install_github("ksatohds/nmfkc")
# Example 1. Matrix Mode (Existing)
library(nmfkc)
X <- cbind(c(1,0,1),c(0,1,0))
B <- cbind(c(1,0),c(0,1),c(1,1))
Y <- X \%*\% B
rownames(Y) <- paste0("P",1:nrow(Y))
colnames(Y) <- paste0("N",1:ncol(Y))
print(X); print(B); print(Y)
library(nmfkc)
res <- nmfkc(Y,Q=2,epsilon=1e-6)
res$X
res$B

# Example 2. Formula Mode (New)
# dummy_data <- data.frame(Y1=rpois(10,5), Y2=rpois(10,10), A1=1:10, A2=rnorm(10,5))
# res_f <- nmfkc(Y1 + Y2 ~ A1 + A2, data=dummy_data, rank=2)

}
\references{
Ding, C., Li, T., Peng, W., & Park, H. (2006). Orthogonal Nonnegative Matrix Tri-Factorizations for Clustering.
In \emph{Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining} (pp. 126–135).
\doi{10.1145/1150402.1150420}
Potthoff, R. F., & Roy, S. N. (1964). A generalized multivariate analysis of variance model useful especially for growth curve problems.
\emph{Biometrika}, 51, 313–326. \doi{10.2307/2334137}
}
\seealso{
\code{\link{nmfkc.cv}}, \code{\link{nmfkc.rank}}, \code{\link{nmfkc.kernel}}, \code{\link{nmfkc.ar}}, \code{\link{predict.nmfkc}}
}
